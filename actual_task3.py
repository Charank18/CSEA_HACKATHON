# -*- coding: utf-8 -*-
"""ACTUAL_TASK3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mDR7PiRyaKsWBODTNG_6sVeHAh0qHDJ-
"""

!pip install tensorflow transformers pandas scikit-learn

!pip install datasets

pip install tf_keras

pip install detoxify







#LAST CODE

import torch
import pandas as pd
import numpy as np
from detoxify import Detoxify
from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

# Check for GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load Detoxify model once (avoid reloading)
detox_model = Detoxify('original', device=device)

# Function to get toxicity scores
def get_toxicity_scores(texts):
    results = detox_model.predict(texts)
    return results['toxicity']

# Function to map toxicity score to labels
def map_toxicity(score):
    if score > 0.5:
        return 2  # Toxic
    elif score <= 0.2:
        return 0  # Non-toxic
    else:
        return 1  # Neutral

# Load dataset
df = pd.read_csv('/content/final_labels.csv')

# Drop missing values & convert to string
df = df.dropna(subset=['body'])
df['body'] = df['body'].astype(str)

# Use only 3000 sentences for mapping
df_sample = df.sample(n=1000, random_state=42)

# Process toxicity scores in batches
batch_size = 16
toxicity_scores = []
for i in range(0, len(df_sample), batch_size):
    batch_texts = df_sample['body'].iloc[i:i+batch_size].tolist()
    batch_scores = get_toxicity_scores(batch_texts)
    toxicity_scores.extend(batch_scores)

# Assign labels
df_sample['toxicity_score'] = toxicity_scores
df_sample['label'] = df_sample['toxicity_score'].apply(map_toxicity)

# Split into train (80%) and test (20%)
train_df, test_df = train_test_split(df_sample, train_size=0.8, stratify=df_sample['label'], random_state=42)

# Load tokenizer
tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')

# # Define dataset class
# class ToxicityDataset(Dataset):
#     def __init__(self, texts, labels):
#         self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)
#         self.labels = labels

#     def __len__(self):
#         return len(self.labels)

#     def __getitem__(self, idx):
#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, torch.tensor(self.labels[idx])

# # Prepare datasets
# train_dataset = ToxicityDataset(train_df['body'].tolist(), train_df['label'].tolist())
# test_dataset = ToxicityDataset(test_df['body'].tolist(), test_df['label'].tolist())

# # Load model
# model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3).to(device)

# # Define training arguments
# training_args = TrainingArguments(
#     output_dir='./results',
#     num_train_epochs=3,
#     per_device_train_batch_size=8,
#     per_device_eval_batch_size=8,
#     warmup_steps=500,
#     weight_decay=0.01,
#     logging_dir='./logs',
#     logging_steps=10,
#     evaluation_strategy="epoch"
# )

# # Trainer setup
# trainer = Trainer(
#     model=model,
#     args=training_args,
#     train_dataset=train_dataset,
#     eval_dataset=test_dataset  # Using test data for evaluation
# )

# # Train model
# trainer.train()

# # Save model
# model.save_pretrained('/content/saved_model')
# tokenizer.save_pretrained('/content/saved_model')

# print("Model training completed and saved!")

# # Evaluation
# trainer.evaluate()

class ToxicityDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64, return_tensors="pt")
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

# Prepare datasets
train_dataset = ToxicityDataset(train_df['body'].tolist(), train_df['label'].tolist())
test_dataset = ToxicityDataset(test_df['body'].tolist(), test_df['label'].tolist())

# Load model
model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3).to(device)

# Define training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch"
)

# Trainer setup
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset  # Using test data for evaluation
)

# Train model
trainer.train()

# Save model
model.save_pretrained('/content/saved_model')
tokenizer.save_pretrained('/content/saved_model')

print("Model training completed and saved!")

# Evaluation
trainer.evaluate()

from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix
import torch
import numpy as np
from torch.utils.data import DataLoader

# Create DataLoader for test dataset
test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Move model to evaluation mode
model.eval()

# Store predictions, probabilities, and actual labels
all_predictions = []
all_probs = []  # For storing probability scores
all_labels = []

# Disable gradient computation for evaluation
with torch.no_grad():
    for batch in test_dataloader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != "labels"}
        labels = batch["labels"].to(device)

        outputs = model(**inputs)
        logits = outputs.logits

        # Get predicted class
        predictions = torch.argmax(logits, dim=-1)

        # For binary classification, get probability of positive class
        # For multi-class, you might need to adjust this
        probs = torch.softmax(logits, dim=-1)

        all_predictions.extend(predictions.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Convert to numpy arrays
all_predictions = np.array(all_predictions)
all_labels = np.array(all_labels)
all_probs = np.array(all_probs)

# Calculate accuracy
accuracy = accuracy_score(all_labels, all_predictions)
print(f"Test Accuracy: {accuracy:.4f}")

# For binary classification
if len(np.unique(all_labels)) == 2:
    # Get probabilities for positive class
    pos_probs = all_probs[:, 1]

    # Calculate AUC-ROC
    roc_auc = roc_auc_score(all_labels, pos_probs)
    print(f"AUC-ROC: {roc_auc:.4f}")

    # Calculate AUC-PR (Precision-Recall AUC)
    precision, recall, _ = precision_recall_curve(all_labels, pos_probs)
    pr_auc = auc(recall, precision)
    print(f"AUC-PR: {pr_auc:.4f}")

    # Calculate confusion matrix
    tn, fp, fn, tp = confusion_matrix(all_labels, all_predictions).ravel()

    # Calculate FPR and FNR
    fpr = fp / (fp + tn)  # False Positive Rate
    fnr = fn / (fn + tp)  # False Negative Rate

    print(f"False Positive Rate (FPR): {fpr:.4f}")
    print(f"False Negative Rate (FNR): {fnr:.4f}")

# For multi-class classification
else:
    # Calculate AUC-ROC using one-vs-rest approach
    try:
        roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')
        print(f"AUC-ROC (one-vs-rest): {roc_auc:.4f}")
    except ValueError:
        print("Could not calculate AUC-ROC for multi-class.")

    # For multi-class, display confusion matrix
    cm = confusion_matrix(all_labels, all_predictions)
    print("Confusion Matrix:")
    print(cm)

    # Calculate class-wise FPR and FNR
    num_classes = len(np.unique(all_labels))
    for i in range(num_classes):
        # Create binary labels (class i vs. rest)
        binary_labels = (all_labels == i).astype(int)
        binary_preds = (all_predictions == i).astype(int)

        # Calculate confusion matrix for this class
        tn, fp, fn, tp = confusion_matrix(binary_labels, binary_preds).ravel()

        # Calculate FPR and FNR for this class
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0

        print(f"Class {i} - FPR: {fpr:.4f}, FNR: {fnr:.4f}")

from sklearn.metrics import accuracy_score
import torch
import numpy as np
from torch.utils.data import DataLoader

# Create DataLoader for test dataset
test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Move model to evaluation mode
model.eval()

# Store predictions and actual labels
all_predictions = []
all_labels = []

# Disable gradient computation for evaluation
with torch.no_grad():
    for batch in test_dataloader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != "labels"}
        labels = batch["labels"].to(device)

        outputs = model(**inputs)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)

        all_predictions.extend(predictions.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calculate accuracy
accuracy = accuracy_score(all_labels, all_predictions)
print(f"Test Accuracy: {accuracy:.2f}")



import torch
from transformers import RobertaTokenizerFast, RobertaForSequenceClassification

# Load trained model and tokenizer
model_path = "/content/saved_model"
tokenizer = RobertaTokenizerFast.from_pretrained(model_path)
model = RobertaForSequenceClassification.from_pretrained(model_path).to("cuda" if torch.cuda.is_available() else "cpu")
model.eval()  # Set model to evaluation mode

# Label Mapping
LABEL_MAP = {0: "Non-Toxic", 1: "Neutral", 2: "Toxic"}

# Function to classify comments
def classify_comments(comments):
    """Classify comments into Non-Toxic, Neutral, or Toxic."""
    inputs = tokenizer(comments, truncation=True, padding=True, max_length=64, return_tensors="pt")

    # Move inputs to GPU if available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    inputs = {key: val.to(device) for key, val in inputs.items()}

    # Get model predictions
    with torch.no_grad():
        outputs = model(**inputs)

    # Convert logits to probabilities and get predicted class
    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()

    return [LABEL_MAP[pred] for pred in predictions]
def suggest_rephrasing(comment, classification):
    """Suggest positive rephrasings for toxic comments."""
    if classification == "Toxic":
        replacements = {
            "stupid": "misguided",
            "idiot": "uninformed person",
            "hate": "strongly dislike",
            "dumb": "not well thought out",
            "ugly": "not aesthetically pleasing",
            "shut up": "please consider listening",
            "trash": "not very useful"
        }

        for toxic, polite in replacements.items():
            comment = comment.replace(toxic, polite)

        return f"Consider rephrasing: {comment}"

    return comment  # No change if not toxic


# Test new comments
test_comments = [
    "You are so stupid and annoying!",
    "I disagree with your point, but I respect your opinion.",
    "This is a great idea, thank you for sharing!",
    "You are an idiot, I hate your comments."
]

# Classify comments
results = classify_comments(test_comments)

# Display results
for comment, classification in zip(test_comments, results):
    rephrased = suggest_rephrasing(comment, classification)
    print(f"Original: {comment}\nPrediction: {classification}\nSuggested Rephrasing: {rephrased}\n")

! pip install huggingface_hub

from huggingface_hub import login

# Log in to Hugging Face
login()

from huggingface_hub import HfApi

api = HfApi()
api.create_repo(
    repo_id="Charankarnati18/TASK3",  # This will be your model name
    repo_type="model",
    private=False  # Set to True if you want it private
)

api.upload_folder(
    folder_path="/content/saved_model",  # Path where your model is saved
    repo_id="Charankarnati18/TASK3",
    repo_type="model",
    commit_message="Uploading fine-tuned summarization model"
)

